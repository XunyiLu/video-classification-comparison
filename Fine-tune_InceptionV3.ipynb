{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLPLt+ybaIl+/huqTjo35w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_imE6jvNrefh","executionInfo":{"status":"ok","timestamp":1681937320131,"user_tz":-60,"elapsed":24192,"user":{"displayName":"Xunyi Lu","userId":"03671529717609113475"}},"outputId":"c6ff5839-c1e4-413a-a1ba-1fafe21e633b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"code","source":["from tensorflow import keras\n","import pandas as pd\n","train_df = pd.read_csv('/content/train_df_test.csv')\n","label_processor = keras.layers.StringLookup(\n","    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",")\n","print(label_processor.get_vocabulary())\n"],"metadata":{"id":"uw1s_3DMsSMO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Process an image that we can pass to our networks.\n","\"\"\"\n","from keras.utils import img_to_array, load_img\n","import numpy as np\n","\n","def process_image(image, target_shape):\n","    \"\"\"Given an image, process it and return the array.\"\"\"\n","    # Load the image.\n","    h, w, _ = target_shape\n","    image = load_img(image, target_size=(h, w))\n","\n","    # Turn it into numpy, normalize and return.\n","    img_arr = img_to_array(image)\n","    x = (img_arr / 255.).astype(np.float32)\n","\n","    return x"],"metadata":{"id":"1TKH9YepQ958"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Class for managing our data.\n","\"\"\"\n","import csv\n","import numpy as np\n","import random\n","import glob\n","import os.path\n","import sys\n","import operator\n","import threading\n","# from processor import process_image\n","from keras.utils import to_categorical\n","\n","class threadsafe_iterator:\n","    def __init__(self, iterator):\n","        self.iterator = iterator\n","        self.lock = threading.Lock()\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        with self.lock:\n","            return next(self.iterator)\n","\n","def threadsafe_generator(func):\n","    \"\"\"Decorator\"\"\"\n","    def gen(*a, **kw):\n","        return threadsafe_iterator(func(*a, **kw))\n","    return gen\n","\n","class DataSet():\n","\n","    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n","        \"\"\"Constructor.\n","        seq_length = (int) the number of frames to consider\n","        class_limit = (int) number of classes to limit the data to.\n","            None = no limit.\n","        \"\"\"\n","        self.seq_length = seq_length\n","        self.class_limit = class_limit\n","        self.sequence_path = os.path.join('data', 'sequences')\n","        self.max_frames = 300  # max number of frames a video can have for us to use it\n","\n","        # Get the data.\n","        self.data = self.get_data()\n","\n","        # Get the classes.\n","        self.classes = self.get_classes()\n","\n","        # Now do some minor data cleaning.\n","        self.data = self.clean_data()\n","\n","        self.image_shape = image_shape\n","\n","    @staticmethod\n","    def get_data():\n","        \"\"\"Load our data from file.\"\"\"\n","        with open(os.path.join('/content/gdrive/MyDrive/data_file.csv'), 'r') as fin:\n","            reader = csv.reader(fin)\n","            data = list(reader)\n","\n","        return data\n","\n","    def clean_data(self):\n","        \"\"\"Limit samples to greater than the sequence length and fewer\n","        than N frames. Also limit it to classes we want to use.\"\"\"\n","        data_clean = []\n","        for item in self.data:\n","            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n","                    and item[1] in self.classes:\n","                data_clean.append(item)\n","\n","        return data_clean\n","\n","    def get_classes(self):\n","        \"\"\"Extract the classes from our data. If we want to limit them,\n","        only return the classes we need.\"\"\"\n","        classes = []\n","        for item in self.data:\n","            if item[1] not in classes:\n","                classes.append(item[1])\n","\n","        # Sort them.\n","        classes = sorted(classes)\n","\n","        # Return.\n","        if self.class_limit is not None:\n","            return classes[:self.class_limit]\n","        else:\n","            return classes\n","\n","    def get_class_one_hot(self, class_str):\n","        \"\"\"Given a class as a string, return its number in the classes\n","        list. This lets us encode and one-hot it for training.\"\"\"\n","        # Encode it first.\n","        label_encoded = self.classes.index(class_str)\n","\n","        # Now one-hot it.\n","        label_hot = to_categorical(label_encoded, len(self.classes))\n","\n","        assert len(label_hot) == len(self.classes)\n","\n","        return label_hot\n","\n","    def split_train_test(self):\n","        \"\"\"Split the data into train and test groups.\"\"\"\n","        train = []\n","        test = []\n","        for item in self.data:\n","            if item[0] == 'train':\n","                train.append(item)\n","            else:\n","                test.append(item)\n","        return train, test\n","\n","    def get_all_sequences_in_memory(self, train_test, data_type):\n","        \"\"\"\n","        This is a mirror of our generator, but attempts to load everything into\n","        memory so we can train way faster.\n","        \"\"\"\n","        # Get the right dataset.\n","        train, test = self.split_train_test()\n","        data = train if train_test == 'train' else test\n","\n","        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n","\n","        X, y = [], []\n","        for row in data:\n","\n","            if data_type == 'images':\n","                frames = self.get_frames_for_sample(row)\n","                frames = self.rescale_list(frames, self.seq_length)\n","\n","                # Build the image sequence\n","                sequence = self.build_image_sequence(frames)\n","\n","            else:\n","                sequence = self.get_extracted_sequence(data_type, row)\n","\n","                if sequence is None:\n","                    print(\"Can't find sequence. Did you generate them?\")\n","                    raise\n","\n","            X.append(sequence)\n","            y.append(self.get_class_one_hot(row[1]))\n","\n","        return np.array(X), np.array(y)\n","\n","    @threadsafe_generator\n","    def frame_generator(self, batch_size, train_test, data_type):\n","        \"\"\"Return a generator that we can use to train on. There are\n","        a couple different things we can return:\n","\n","        data_type: 'features', 'images'\n","        \"\"\"\n","        # Get the right dataset for the generator.\n","        train, test = self.split_train_test()\n","        data = train if train_test == 'train' else test\n","\n","        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n","\n","        while 1:\n","            X, y = [], []\n","\n","            # Generate batch_size samples.\n","            for _ in range(batch_size):\n","                # Reset to be safe.\n","                sequence = None\n","\n","                # Get a random sample.\n","                sample = random.choice(data)\n","\n","                # Check to see if we've already saved this sequence.\n","                if data_type == \"images\":\n","                    # Get and resample frames.\n","                    frames = self.get_frames_for_sample(sample)\n","                    frames = self.rescale_list(frames, self.seq_length)\n","\n","                    # Build the image sequence\n","                    sequence = self.build_image_sequence(frames)\n","                else:\n","                    # Get the sequence from disk.\n","                    sequence = self.get_extracted_sequence(data_type, sample)\n","\n","                    if sequence is None:\n","                        raise ValueError(\"Can't find sequence. Did you generate them?\")\n","\n","                X.append(sequence)\n","                y.append(self.get_class_one_hot(sample[1]))\n","\n","            yield np.array(X), np.array(y)\n","\n","    def build_image_sequence(self, frames):\n","        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n","        return [process_image(x, self.image_shape) for x in frames]\n","\n","    def get_extracted_sequence(self, data_type, sample):\n","        \"\"\"Get the saved extracted features.\"\"\"\n","        filename = sample[2]\n","        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n","            '-' + data_type + '.npy')\n","        if os.path.isfile(path):\n","            return np.load(path)\n","        else:\n","            return None\n","\n","    def get_frames_by_filename(self, filename, data_type):\n","        \"\"\"Given a filename for one of our samples, return the data\n","        the model needs to make predictions.\"\"\"\n","        # First, find the sample row.\n","        sample = None\n","        for row in self.data:\n","            if row[2] == filename:\n","                sample = row\n","                break\n","        if sample is None:\n","            raise ValueError(\"Couldn't find sample: %s\" % filename)\n","\n","        if data_type == \"images\":\n","            # Get and resample frames.\n","            frames = self.get_frames_for_sample(sample)\n","            frames = self.rescale_list(frames, self.seq_length)\n","            # Build the image sequence\n","            sequence = self.build_image_sequence(frames)\n","        else:\n","            # Get the sequence from disk.\n","            sequence = self.get_extracted_sequence(data_type, sample)\n","\n","            if sequence is None:\n","                raise ValueError(\"Can't find sequence. Did you generate them?\")\n","\n","        return sequence\n","\n","    @staticmethod\n","    def get_frames_for_sample(sample):\n","        \"\"\"Given a sample row from the data file, get all the corresponding frame\n","        filenames.\"\"\"\n","        path = os.path.join('/content/gdrive/MyDrive/', sample[0], sample[1])\n","        filename = sample[2]\n","        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n","        return images\n","\n","    @staticmethod\n","    def get_filename_from_image(filename):\n","        parts = filename.split(os.path.sep)\n","        return parts[-1].replace('.jpg', '')\n","\n","    @staticmethod\n","    def rescale_list(input_list, size):\n","        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n","        if we want a list of size 5 and we have a list of size 25, return a new\n","        list of size five which is every 5th element of the origina list.\"\"\"\n","        assert len(input_list) >= size\n","\n","        # Get the number to skip between iterations.\n","        skip = len(input_list) // size\n","\n","        # Build our new output.\n","        output = [input_list[i] for i in range(0, len(input_list), skip)]\n","\n","        # Cut off the last one if needed.\n","        return output[:size]\n","\n","    def print_class_from_prediction(self, predictions, nb_to_return=5):\n","        \"\"\"Given a prediction, print the top classes.\"\"\"\n","        # Get the prediction for each label.\n","        label_predictions = {}\n","        for i, label in enumerate(self.classes):\n","            label_predictions[label] = predictions[i]\n","\n","        # Now sort them.\n","        sorted_lps = sorted(\n","            label_predictions.items(),\n","            key=operator.itemgetter(1),\n","            reverse=True\n","        )\n","\n","        # And return the top N.\n","        for i, class_prediction in enumerate(sorted_lps):\n","            if i > nb_to_return - 1 or class_prediction[1] == 0.0:\n","                break\n","            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))"],"metadata":{"id":"hFhcjroQv7de"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = DataSet()\n","print(data.image_shape)"],"metadata":{"id":"ZI8OxjgwUwIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Train on images split into directories. This assumes we've split\n","our videos into frames and moved them to their respective folders.\n","\n","Based on:\n","https://keras.io/preprocessing/image/\n","and\n","https://keras.io/applications/\n","\"\"\"\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n","from keras.regularizers import l2\n","# from data import DataSet\n","import os.path\n","\n","\n","# Helper: Save the model.\n","checkpointer = ModelCheckpoint(\n","    filepath=os.path.join('/content/gdrive/MyDrive/', 'checkpoints', 'inception.{epoch:03d}-{val_loss:.2f}.hdf5'),\n","    verbose=1,\n","    save_best_only=True)\n","\n","# Helper: Stop when we stop learning.\n","early_stopper = EarlyStopping(patience=5)\n","\n","# Helper: TensorBoard\n","tensorboard = TensorBoard(log_dir=os.path.join('/content/gdrive/MyDrive/', 'logs'))\n","\n","def get_generators():\n","    train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        horizontal_flip=True,\n","        rotation_range=10.,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2)\n","\n","    test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    train_generator = train_datagen.flow_from_directory(\n","        os.path.join('/content/gdrive/MyDrive/', 'train'),\n","        target_size=(224, 224),\n","        batch_size=32,\n","        classes=data.classes,\n","        class_mode='categorical')\n","\n","    validation_generator = test_datagen.flow_from_directory(\n","        os.path.join('/content/gdrive/MyDrive/', 'test'),\n","        target_size=(224, 224),\n","        batch_size=32,\n","        classes=data.classes,\n","        class_mode='categorical')\n","\n","    return train_generator, validation_generator\n","\n","def get_model(weights='imagenet'):\n","    # create the base pre-trained model\n","    base_model = InceptionV3(weights=weights, include_top=False)\n","\n","    # add a global spatial average pooling layer\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(0.3)(x)\n","    # let's add a fully-connected layer\n","    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n","    # and a logistic layer\n","    x = Dropout(0.3)(x)\n","    predictions = Dense(len(data.classes), activation='softmax')(x)\n","\n","    # this is the model we will train\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return model\n","\n","def freeze_all_but_top(model):\n","    \"\"\"Used to train just the top layers of the model.\"\"\"\n","    # first: train only the top layers (which were randomly initialized)\n","    # i.e. freeze all convolutional InceptionV3 layers\n","    for layer in model.layers[:-2]:\n","        layer.trainable = False\n","\n","    # compile the model (should be done *after* setting layers to non-trainable)\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","def freeze_all_but_mid_and_top(model):\n","    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n","    # we chose to train the top 2 inception blocks, i.e. we will freeze\n","    # the first 172 layers and unfreeze the rest:\n","    for layer in model.layers[:172]:\n","        layer.trainable = False\n","    for layer in model.layers[172:]:\n","        layer.trainable = True\n","\n","    # we need to recompile the model for these modifications to take effect\n","    # we use SGD with a low learning rate\n","    model.compile(\n","        optimizer=SGD(lr=0.0001, momentum=0.9),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy', 'top_k_categorical_accuracy'])\n","\n","    return model\n","\n","def train_model(model, nb_epoch, generators, callbacks=[]):\n","    train_generator, validation_generator = generators\n","    model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=100,\n","        validation_data=validation_generator,\n","        validation_steps=10,\n","        epochs=nb_epoch,\n","        callbacks=callbacks)\n","    return model\n","\n","def main(weights_file):\n","    model = get_model()\n","    generators = get_generators()\n","\n","    if weights_file is None:\n","        print(\"Loading network from ImageNet weights.\")\n","        # Get and train the top layers.\n","        model = freeze_all_but_top(model)\n","        model = train_model(model, 5, generators)\n","    else:\n","        print(\"Loading saved model: %s.\" % weights_file)\n","        model.load_weights(weights_file)\n","\n","    # Get and train the mid layers.\n","    model = freeze_all_but_mid_and_top(model)\n","    model = train_model(model, 50, generators,\n","                        [checkpointer, early_stopper, tensorboard])\n","\n","if __name__ == '__main__':\n","    weights_file = None\n","    main(weights_file)"],"metadata":{"id":"I9G9URvITT-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install chardet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fbt-xe7dEZ6w","executionInfo":{"status":"ok","timestamp":1681934139872,"user_tz":-60,"elapsed":5298,"user":{"displayName":"Xunyi Lu","userId":"03671529717609113475"}},"outputId":"d00f153d-38b3-40db-c81d-1e801e5ff7b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: chardet in /usr/local/lib/python3.9/dist-packages (4.0.0)\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","epochs = []\n","for i in range(1,19+1):\n","    epochs.append(i)\n","\n","# train_loss = [14.3309, 14.2507, 14.1935, 14.1300, 14.0774, 14.0774, 13.9997, 13.9997]\n","print(epochs)\n","\n","# epochs = [1, 2, 3, 4, 5]\n","# train_loss = [1.0295, 0.6733, 0.6358, 0.6032, 0.5464]\n","# train_acc = [0.5481, 0.6103, 0.6275, 0.6459, 0.6981]\n","# val_loss = [0.7613, 0.8200, 0.8396, 0.9514, 1.1158]\n","# val_acc = [0.5813, 0.5125, 0.5531, 0.5781, 0.4844]\n","\n","# Plot the training and validation loss\n","plt.figure()\n","plt.plot(epochs, train_loss, label=\"Training Loss\")\n","plt.plot(epochs, val_loss, label=\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.title(\"Training and Validation Loss\")\n","plt.show()\n","\n","# # Plot the training and validation accuracy\n","plt.figure()\n","plt.plot(epochs, train_acc, label=\"Training Accuracy\")\n","plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.title(\"Training and Validation Accuracy\")\n","plt.show()\n","\n"],"metadata":{"id":"39r2dQ1p1Zc6"},"execution_count":null,"outputs":[]}]}